{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb9ef829-2580-488c-951a-f5f7ca6d49d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_community.embeddings.cohere import CohereEmbeddings\n",
    "from langchain.llms import Cohere\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b052f615-b227-464f-bfda-8c4facc01c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Étape 1 : Charger les documents PDF\n",
    "import os\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "def load_documents(folder_path):\n",
    "    documents = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".pdf\"):\n",
    "            with open(os.path.join(folder_path, filename), 'rb') as file:\n",
    "                reader = PdfReader(file)\n",
    "                text = \"\"\n",
    "                for page in reader.pages:\n",
    "                    text += page.extract_text()\n",
    "                documents.append(text)  # Ajouter le texte extrait à la liste\n",
    "    return documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "eec63073-2a62-4129-b69c-cb99d80c47de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents chargés : [\"Certificat de formation  de juge de Double Dutch  \\n \\n \\n \\nNous, soussignés, certifions que Assa Traoré  a suivi avec succès la formation de Juge de \\nDouble Dutch  organisée par la Fédération Française de Double Dutch  en 2020 . \\nCette formation couvre l'évaluation des compétences nécessaires pour juger les compétitions \\nde Double Dutch, y compris la compréhension des règles, des critères de jugement et des \\nprocédures officielles. Par la présente, nous attestons que Assa Traoré  a acquis les \\ncompétences requises pour exercer en tant que juge dans ce domaine.  \\nFait à Vitry -sur-Seine  le 3 décembre 2020 . \\n \\n \\n \\n \\n \\n \\nNom  : Jonathan Mahoto  \\nPoste  : Directeur de la FFDD  \\n \\n                                                               \\n \\n \\n \\n                                                                                                                                       \\n\", \"Assa Traoré\\nData analy st\\nMaster MASERA TI\\nUPE C Créteil\\nLogiciel e t langag e de pr ogramma tion\\nSéries t empor elles\\nÉconomé trie\\nAnalyse de données\\nDU - I ntelligence Artiﬁcielle\\nUPE C Créteil\\nMachine L earning\\nDeep L earning\\nSpark\\nLogique e t programma tion\\nAlgorithme a vancée\\nLicence économie e t gestion\\nUPE C Créteil\\nMicroéconomie\\nMacroéconomie\\nProcessus st ochastique\\nÉconomé trie\\nFinanc e\\nComptabilit é\\nBaccalaur éat\\nLycée Jean-B aptiste Corot Savigny-sur -Orge\\nSpécialit é : M aths - SES - HGGSP\\nServic e Civique\\nNo Limit Jump Grigny\\nMise en plac e d'événemen ts sportifs e t cultur elles pour  les en fants n'ayant pas pu aller  en vacanc es à cause du c ontexte pandémique\\nde cet été\\nAide aux de voirs\\nMaire de G rigny Grigny\\nAccompagnemen t des élè ves dans leur s révisions\\nPropositions d' exercices supplémen taires\\nAide à l' apprentissag e des leç ons\\nÉquipièr e polyv alente\\nMcDonald' s Grigny\\nFerme ture du r estaur ant\\nInventaire et contrôle des niv eaux des st ocks\\nApplica tion des pr océdures de f erme ture\\nPréparatrice de c ommande\\nAmazon Brétigny-sur -Orge\\nContrôle de la qualit é\\nSuivi des niv eaux de st ocks\\nPréparation des c ommandes\\nHôtesse de caisse\\nBricoman Monthléry\\nEncaissemen t de la clien tèle\\nGestion des r etours\\nConseille clien tèle\\nGestion des c ommandes driv e\\nSonink é\\nLangue ma ternelle\\nAnglais\\n› TOEIC : 731/990\\nEspagnolSport\\nLectur e\\nVoyagePrism\\nSAS\\nR\\nPython\\uf0e0traore.assa16@gmail.c om\\n\\uf015Grigny (91350)\\n\\uf073Née le 16/01/2004\\n\\uf109Télétravail ou pr ésentiel\\uf2c3Permis B1\\n\\uf1b9Véhicule per sonnel\\n\\uf041Ile-de-F rance\\n\\uf09807 69 88 07 32\\nDipl ômes et  Formations\\nDe\\nseptembr e\\n2024  à août\\n2026\\nDe\\nseptembr e\\n2024  à août\\n2026\\nDe\\nseptembr e\\n2021  à juin\\n2024\\nDe\\nseptembr e\\n2018  à\\njuillet 2021\\nExpé riences pr ofessionnell es\\nDe\\nnovembr e\\n2020  à juin\\n2021\\nDe\\nseptembr e\\n2021  à avril\\n2022\\nD'avril 2022\\nà avril 2023\\nDe juillet\\n2024  à\\nseptembr e\\n2024\\nDe juin\\n2023  à avril\\n2024\\nLangues Loisirs Informatique\", '']\n"
     ]
    }
   ],
   "source": [
    "documents = load_documents(r\"C:\\Users\\maserati\\Desktop\\rag_llm\")\n",
    "print(\"Documents chargés :\", documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "00ca859d-8e7c-4d28-9404-fb81a0fc2b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents nettoyés : [\"Certificat de formation de juge de Double Dutch Nous, soussignés, certifions que Assa Traoré a suivi avec succès la formation de Juge de Double Dutch organisée par la Fédération Française de Double Dutch en 2020 . Cette formation couvre l'évaluation des compétences nécessaires pour juger les compétitions de Double Dutch, y compris la compréhension des règles, des critères de jugement et des procédures officielles. Par la présente, nous attestons que Assa Traoré a acquis les compétences requises pour exercer en tant que juge dans ce domaine. Fait à Vitry -sur-Seine le 3 décembre 2020 . Nom : Jonathan Mahoto Poste : Directeur de la FFDD\", \"Assa Traoré Data analy st Master MASERA TI UPE C Créteil Logiciel e t langag e de pr ogramma tion Séries t empor elles Économé trie Analyse de données DU - I ntelligence Artiﬁcielle UPE C Créteil Machine L earning Deep L earning Spark Logique e t programma tion Algorithme a vancée Licence économie e t gestion UPE C Créteil Microéconomie Macroéconomie Processus st ochastique Économé trie Financ e Comptabilit é Baccalaur éat Lycée Jean-B aptiste Corot Savigny-sur -Orge Spécialit é : M aths - SES - HGGSP Servic e Civique No Limit Jump Grigny Mise en plac e d'événemen ts sportifs e t cultur elles pour les en fants n'ayant pas pu aller en vacanc es à cause du c ontexte pandémique de cet été Aide aux de voirs Maire de G rigny Grigny Accompagnemen t des élè ves dans leur s révisions Propositions d' exercices supplémen taires Aide à l' apprentissag e des leç ons Équipièr e polyv alente McDonald' s Grigny Ferme ture du r estaur ant Inventaire et contrôle des niv eaux des st ocks Applica tion des pr océdures de f erme ture Préparatrice de c ommande Amazon Brétigny-sur -Orge Contrôle de la qualit é Suivi des niv eaux de st ocks Préparation des c ommandes Hôtesse de caisse Bricoman Monthléry Encaissemen t de la clien tèle Gestion des r etours Conseille clien tèle Gestion des c ommandes driv e Sonink é Langue ma ternelle Anglais › TOEIC : 731/990 EspagnolSport Lectur e VoyagePrism SAS R Pythontraore.assa16@gmail.c om Grigny (91350) Née le 16/01/2004 Télétravail ou pr ésentielPermis B1 Véhicule per sonnel Ile-de-F rance 07 69 88 07 32 Dipl ômes et Formations De septembr e 2024 à août 2026 De septembr e 2024 à août 2026 De septembr e 2021 à juin 2024 De septembr e 2018 à juillet 2021 Expé riences pr ofessionnell es De novembr e 2020 à juin 2021 De septembr e 2021 à avril 2022 D'avril 2022 à avril 2023 De juillet 2024 à septembr e 2024 De juin 2023 à avril 2024 Langues Loisirs Informatique\", '']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_documents(documents):\n",
    "    \"\"\"\n",
    "    Nettoie les documents en supprimant les caractères inutiles et les espaces excessifs.\n",
    "    \"\"\"\n",
    "    cleaned_documents = []\n",
    "    \n",
    "    for doc in documents:\n",
    "        # Nettoyage du texte\n",
    "        cleaned_text = re.sub(r'\\n+', ' ', doc)  # Remplace les retours à la ligne multiples par un espace\n",
    "        cleaned_text = re.sub(r'\\uf0e0|\\uf015|\\uf073|\\uf109|\\uf2c3|\\uf1b9|\\uf041|\\uf098', '', cleaned_text)  # Supprime les caractères spéciaux\n",
    "        cleaned_text = re.sub(r'\\s+', ' ', cleaned_text)  # Remplace les espaces multiples par un seul espace\n",
    "        cleaned_text = cleaned_text.strip()  # Supprime les espaces en début et fin de texte\n",
    "        \n",
    "        # Ajouter le texte nettoyé à la liste\n",
    "        cleaned_documents.append(cleaned_text)\n",
    "    \n",
    "    return cleaned_documents\n",
    "\n",
    "# Nettoyer les documents après les avoir chargés\n",
    "cleaned_documents = clean_documents(documents)\n",
    "print(\"Documents nettoyés :\", cleaned_documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1e04df72-f73b-4185-a1f2-7041274822fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Étape 2 : Fractionner les documents en chunks\n",
    "from langchain.schema import Document\n",
    "\n",
    "def create_documents(texts):\n",
    "    \"\"\"\n",
    "    Crée des objets Document à partir des textes nettoyés.\n",
    "    \"\"\"\n",
    "    documents2 = []\n",
    "    for text in texts:\n",
    "        doc = Document(page_content=text, metadata={})  # Vous pouvez ajouter des métadonnées si nécessaire\n",
    "        documents2.append(doc)\n",
    "    return documents2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "67874902-fe71-4e23-aeaa-91ece49e1a80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content=\"Certificat de formation de juge de Double Dutch Nous, soussignés, certifions que Assa Traoré a suivi avec succès la formation de Juge de Double Dutch organisée par la Fédération Française de Double Dutch en 2020 . Cette formation couvre l'évaluation des compétences nécessaires pour juger les compétitions de Double Dutch, y compris la compréhension des règles, des critères de jugement et des procédures officielles. Par la présente, nous attestons que Assa Traoré a acquis les compétences requises pour exercer en tant que juge dans ce domaine. Fait à Vitry -sur-Seine le 3 décembre 2020 . Nom : Jonathan Mahoto Poste : Directeur de la FFDD\"),\n",
       " Document(metadata={}, page_content=\"Assa Traoré Data analy st Master MASERA TI UPE C Créteil Logiciel e t langag e de pr ogramma tion Séries t empor elles Économé trie Analyse de données DU - I ntelligence Artiﬁcielle UPE C Créteil Machine L earning Deep L earning Spark Logique e t programma tion Algorithme a vancée Licence économie e t gestion UPE C Créteil Microéconomie Macroéconomie Processus st ochastique Économé trie Financ e Comptabilit é Baccalaur éat Lycée Jean-B aptiste Corot Savigny-sur -Orge Spécialit é : M aths - SES - HGGSP Servic e Civique No Limit Jump Grigny Mise en plac e d'événemen ts sportifs e t cultur elles pour les en fants n'ayant pas pu aller en vacanc es à cause du c ontexte pandémique de cet été Aide aux de voirs Maire de G rigny Grigny Accompagnemen t des élè ves dans leur s révisions Propositions d' exercices supplémen taires Aide à l' apprentissag e des leç ons Équipièr e polyv alente McDonald' s Grigny Ferme ture du r estaur ant Inventaire et contrôle des niv eaux des st ocks Applica tion des pr océdures de f erme ture Préparatrice de c ommande Amazon Brétigny-sur -Orge Contrôle de la qualit é Suivi des niv eaux de st ocks Préparation des c ommandes Hôtesse de caisse Bricoman Monthléry Encaissemen t de la clien tèle Gestion des r etours Conseille clien tèle Gestion des c ommandes driv e Sonink é Langue ma ternelle Anglais › TOEIC : 731/990 EspagnolSport Lectur e VoyagePrism SAS R Pythontraore.assa16@gmail.c om Grigny (91350) Née le 16/01/2004 Télétravail ou pr ésentielPermis B1 Véhicule per sonnel Ile-de-F rance 07 69 88 07 32 Dipl ômes et Formations De septembr e 2024 à août 2026 De septembr e 2024 à août 2026 De septembr e 2021 à juin 2024 De septembr e 2018 à juillet 2021 Expé riences pr ofessionnell es De novembr e 2020 à juin 2021 De septembr e 2021 à avril 2022 D'avril 2022 à avril 2023 De juillet 2024 à septembr e 2024 De juin 2023 à avril 2024 Langues Loisirs Informatique\"),\n",
       " Document(metadata={}, page_content='')]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents3=create_documents(cleaned_documents)\n",
    "documents3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f13fc129-b551-4dfc-9555-f3eb42a8ad54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunks créés :\n",
      "Certificat de formation de juge de Double Dutch Nous, soussignés, certifions que Assa Traoré a suivi avec succès la formation de Juge de Double Dutch organisée par la Fédération Française de Double Dutch en 2020 . Cette formation couvre l'évaluation des compétences nécessaires pour juger les compétitions de Double Dutch, y compris la compréhension des règles, des critères de jugement et des procédures officielles. Par la présente, nous attestons que Assa Traoré a acquis les compétences requises pour exercer en tant que juge dans ce domaine. Fait à Vitry -sur-Seine le 3 décembre 2020 . Nom : Jonathan Mahoto Poste : Directeur de la FFDD\n",
      "Assa Traoré Data analy st Master MASERA TI UPE C Créteil Logiciel e t langag e de pr ogramma tion Séries t empor elles Économé trie Analyse de données DU - I ntelligence Artiﬁcielle UPE C Créteil Machine L earning Deep L earning Spark Logique e t programma tion Algorithme a vancée Licence économie e t gestion UPE C Créteil Microéconomie Macroéconomie Processus st ochastique Économé trie Financ e Comptabilit é Baccalaur éat Lycée Jean-B aptiste Corot Savigny-sur -Orge Spécialit é : M aths - SES - HGGSP Servic e Civique No Limit Jump Grigny Mise en plac e d'événemen ts sportifs e t cultur elles pour les en fants n'ayant pas pu aller en vacanc es à cause du c ontexte pandémique de cet été Aide aux de voirs Maire de G rigny Grigny Accompagnemen t des élè ves dans leur s révisions Propositions d' exercices supplémen taires Aide à l' apprentissag e des leç ons Équipièr e polyv alente McDonald' s Grigny Ferme ture du r estaur ant Inventaire et contrôle des niv eaux des st ocks Applica tion\n",
      "d' exercices supplémen taires Aide à l' apprentissag e des leç ons Équipièr e polyv alente McDonald' s Grigny Ferme ture du r estaur ant Inventaire et contrôle des niv eaux des st ocks Applica tion des pr océdures de f erme ture Préparatrice de c ommande Amazon Brétigny-sur -Orge Contrôle de la qualit é Suivi des niv eaux de st ocks Préparation des c ommandes Hôtesse de caisse Bricoman Monthléry Encaissemen t de la clien tèle Gestion des r etours Conseille clien tèle Gestion des c ommandes driv e Sonink é Langue ma ternelle Anglais › TOEIC : 731/990 EspagnolSport Lectur e VoyagePrism SAS R Pythontraore.assa16@gmail.c om Grigny (91350) Née le 16/01/2004 Télétravail ou pr ésentielPermis B1 Véhicule per sonnel Ile-de-F rance 07 69 88 07 32 Dipl ômes et Formations De septembr e 2024 à août 2026 De septembr e 2024 à août 2026 De septembr e 2021 à juin 2024 De septembr e 2018 à juillet 2021 Expé riences pr ofessionnell es De novembr e 2020 à juin 2021 De septembr e 2021 à avril 2022 D'avril\n",
      "De septembr e 2024 à août 2026 De septembr e 2021 à juin 2024 De septembr e 2018 à juillet 2021 Expé riences pr ofessionnell es De novembr e 2020 à juin 2021 De septembr e 2021 à avril 2022 D'avril 2022 à avril 2023 De juillet 2024 à septembr e 2024 De juin 2023 à avril 2024 Langues Loisirs Informatique\n"
     ]
    }
   ],
   "source": [
    "# Étape 2 : Fractionner les documents en chunks\n",
    "def split_documents(documents):\n",
    "    \"\"\"\n",
    "    Fractionne les documents en chunks pour l'indexation.\n",
    "    \"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    return text_splitter.split_documents(documents)\n",
    "\n",
    "# Création des documents à partir du texte nettoyé\n",
    "documents = create_documents(cleaned_documents)\n",
    "\n",
    "# Fractionner les documents\n",
    "chunks = split_documents(documents)\n",
    "\n",
    "# Afficher les chunks créés\n",
    "print(\"Chunks créés :\")\n",
    "for chunk in chunks:\n",
    "    print(chunk.page_content)  # Afficher le contenu de chaque chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7b686d9c-33d7-4b85-b6da-e0ed5fbdaacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Étape 3 : Créer un index vectoriel avec Cohere\n",
    "from langchain_community.embeddings.cohere import CohereEmbeddings\n",
    "\n",
    "def create_vectorstore(documents, cohere_api_key):\n",
    "    \"\"\"\n",
    "    Crée un index vectoriel à partir des documents et des embeddings Cohere.\n",
    "    \"\"\"\n",
    "    embeddings = CohereEmbeddings(\n",
    "        cohere_api_key=cohere_api_key,\n",
    "        model=\"embed-english-v2.0\",\n",
    "        user_agent=\"custom_user_agent\"  # Ajout explicite du champ\n",
    "    )\n",
    "    vectorstore = Chroma.from_documents(documents, embeddings)\n",
    "    return vectorstore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c9fefe87-3111-4146-90b0-8f272f902446",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohere_api_key = 'IiVPAkCJc5XsF4abBihOzkj2I7WcYKVH4KgLZMID'  \n",
    "cohere_client = cohere.Client(api_key=cohere_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7aa37566-5867-437f-a22e-d4a8fa2a45f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.chroma.Chroma at 0x13d7b481d80>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_vectorstore(documents3, cohere_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0803ad54-b338-4e39-8d54-c9d7264d2368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Étape 4 : Définir un prompt pour générer un CV\n",
    "def define_prompt():\n",
    "    \"\"\"\n",
    "    Définir un modèle de prompt pour générer un CV structuré.\n",
    "    \"\"\"\n",
    "    template = \"\"\"\n",
    "    Vous êtes un assistant intelligent spécialisé dans la rédaction de CV.\n",
    "    Utilisez les informations suivantes pour générer un CV professionnel structuré :\n",
    "\n",
    "    Informations :\n",
    "    {context}\n",
    "\n",
    "    Structure du CV :\n",
    "    1. Informations personnelles\n",
    "    2. Expérience professionnelle\n",
    "    3. Compétences\n",
    "    4. Certifications et formations\n",
    "    5. Projets\n",
    "\n",
    "    Résultat attendu : \n",
    "    - Un CV bien structuré et rédigé de manière claire et professionnelle.\n",
    "    \"\"\"\n",
    "    return PromptTemplate(template=template, input_variables=[\"context\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c19967ff-92dc-4f3a-8692-16045d83c017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Étape 5 : Interroger le modèle et générer le CV\n",
    "def generate_cv(query, vectorstore, cohere_api_key):\n",
    "    \"\"\"\n",
    "    Génère un CV en utilisant un LLM et un vecteur de recherche.\n",
    "    \"\"\"\n",
    "    retriever = vectorstore.as_retriever()\n",
    "    docs = retriever.get_relevant_documents(query)\n",
    "\n",
    "    # Récupérer le contexte pour le LLM\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "    # Configurer le LLM Cohere\n",
    "    llm = Cohere(cohere_api_key=cohere_api_key, model=\"command-xlarge-nightly\")\n",
    "\n",
    "    # Créer un prompt\n",
    "    prompt = define_prompt()\n",
    "    formatted_prompt = prompt.format(context=context)\n",
    "\n",
    "    # Générer le résultat\n",
    "    result = llm(formatted_prompt)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "bb334ea1-c864-470b-a14b-867d5415d45e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.generate_cv(query, vectorstore, cohere_api_key)>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "36410ab2-8a45-4878-be55-9a507fcdc8a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maserati\\AppData\\Local\\Temp\\ipykernel_14196\\379781450.py:7: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  docs = retriever.get_relevant_documents(query)\n",
      "C:\\Users\\maserati\\AppData\\Local\\Temp\\ipykernel_14196\\379781450.py:13: LangChainDeprecationWarning: The class `Cohere` was deprecated in LangChain 0.1.14 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-cohere package and should be used instead. To use it run `pip install -U :class:`~langchain-cohere` and import as `from :class:`~langchain_cohere import Cohere``.\n",
      "  llm = Cohere(cohere_api_key=cohere_api_key, model=\"command-xlarge-nightly\")\n",
      "C:\\Users\\maserati\\AppData\\Local\\Temp\\ipykernel_14196\\379781450.py:20: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = llm(formatted_prompt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Généré :\n",
      "\n",
      "# CV d'Assa Traoré\n",
      "\n",
      "## Informations personnelles\n",
      "\n",
      "- Adresse e-mail: traore.assa16@gmail.com\n",
      "- Téléphone: 07 69 88 07 32\n",
      "- Date de naissance: 16/01/2004\n",
      "- Adresse: Grigny (91350), France\n",
      "- Permis: B1\n",
      "- Véhicule: Personnel\n",
      "\n",
      "## Expérience professionnelle\n",
      "\n",
      "- **Équipière polyvalente, McDonald's Grigny (juin 2023 - avril 2024):**\n",
      "  - Inventaire et contrôle des stocks\n",
      "  - Application des procédures de fermeture\n",
      "  - Préparation de commande\n",
      "\n",
      "- **Préparatrice de commande, Amazon Brétigny-sur-Orge (avril 2022 - avril 2023):**\n",
      "  - Contrôle de la qualité\n",
      "  - Suivi des niveaux de stocks\n",
      "  - Préparation de commandes\n",
      "\n",
      "- **Hôtesse de caisse, Bricoman Monthléry (septembre 2021 - avril 2022):**\n",
      "  - Encaissement de la clientèle\n",
      "  - Gestion des\n"
     ]
    }
   ],
   "source": [
    "# Étape 6 : Intégrer le tout\n",
    "if __name__ == \"__main__\":\n",
    "    # Configurer la clé API Cohere\n",
    "    COHERE_API_KEY = \"IiVPAkCJc5XsF4abBihOzkj2I7WcYKVH4KgLZMID\"\n",
    "\n",
    "    # Chemin du dossier contenant les CV et certificats\n",
    "    input_folder = r\"C:\\Users\\maserati\\Desktop\\rag_llm\"\n",
    "\n",
    "    # Charger et traiter les documents\n",
    "    documents = load_documents(input_folder)\n",
    "    chunks = split_documents(documents3)\n",
    "\n",
    "    # Créer un vectorstore\n",
    "    vectorstore = create_vectorstore(chunks, COHERE_API_KEY)\n",
    "\n",
    "    # Générer un CV basé sur une requête utilisateur\n",
    "    query = \"Créer un CV basé sur mes expériences et certificats\"\n",
    "    generated_cv = generate_cv(query, vectorstore, COHERE_API_KEY)\n",
    "\n",
    "    # Afficher le CV généré\n",
    "    print(\"CV Généré :\\n\")\n",
    "    print(generated_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "464a0a30-bc7c-4cf0-abaa-1773664f9490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Généré :\n",
      "\n",
      "# CURRICULUM VITAE\n",
      "\n",
      "## Assa Traoré\n",
      "\n",
      "[**Téléphone**] 07 69 88 07 32\n",
      "[**Adresse e-mail**] traore.assa16@gmail.com\n",
      "[**Adresse postale**] Grigny (91350), France\n",
      "\n",
      "## Profil professionnel\n",
      "\n",
      "Je suis un analyste de données motivé, actuellement inscrit au Master MASERATI à l'UPEC Créteil, avec une passion pour l'intelligence artificielle, le machine learning et l'analyse de données. J'ai une expérience pratique dans la gestion des données, la programmation et la résolution de problèmes analytiques complexes. Je cherche à entrer dans le domaine des données pour appliquer mes compétences et contribuer de manière significative à la prise de décisions fondée sur les données.\n",
      "\n",
      "## Expérience professionnelle\n",
      "\n",
      "### Équipière polyvalente, McDonald's Grigny (septembre 2021 - avril 2022)\n",
      "- J'ai participé à différentes tâches de restauration, notamment la préparation des commandes, l'inventaire des stocks et l'application des procédures de fermeture.\n",
      "\n",
      "### Aide aux devoirs, Mairie de Grigny (nov\n"
     ]
    }
   ],
   "source": [
    "def generate_cv2(query, vectorstore, cohere_api_key):\n",
    "    \"\"\"\n",
    "    Utilise un LLM pour générer un CV basé sur la requête et les documents.\n",
    "    \"\"\"\n",
    "    retriever = vectorstore.as_retriever()\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"context\", \"query\"],\n",
    "        template=(\n",
    "            \"En se basant sur les informations suivantes : {context}\\n\"\n",
    "            \"Répondez à la requête suivante : {query}\"\n",
    "        )\n",
    "    )\n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm=CohereEmbeddings(cohere_api_key=cohere_api_key),\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=retriever,\n",
    "        return_source_documents=False\n",
    "    )\n",
    "    return qa_chain.run(query)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Configurer la clé API Cohere\n",
    "    COHERE_API_KEY = \"IiVPAkCJc5XsF4abBihOzkj2I7WcYKVH4KgLZMID\"\n",
    "\n",
    "    # Chemin du dossier contenant les CV et certificats\n",
    "    input_folder = r\"C:\\Users\\maserati\\Desktop\\rag_llm\"\n",
    "\n",
    "    # Charger et traiter les documents\n",
    "    documents = load_documents(input_folder)\n",
    "    if not documents:\n",
    "        raise ValueError(\"Aucun document n'a été chargé.\")\n",
    "    chunks = split_documents(documents3)\n",
    "\n",
    "    # Créer un vectorstore\n",
    "    vectorstore = create_vectorstore(chunks, COHERE_API_KEY)\n",
    "\n",
    "    # Générer un CV basé sur une requête utilisateur\n",
    "    query = \"Créer un CV basé sur mes expériences et certificats\"\n",
    "    generated_cv = generate_cv(query, vectorstore, COHERE_API_KEY)\n",
    "\n",
    "    # Afficher le CV généré\n",
    "    print(\"CV Généré :\\n\")\n",
    "    print(generated_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "fb4b685d-eeb4-4987-887d-37f7c17879d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### CV Généré :\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       " Sure, I can help you create a CV based on the information you've provided. Here's a draft of a CV in respect of the plan you provided;\n",
       "\n",
       "Information:\n",
       "- Full Name: Assa Traoré\n",
       "- Date of Birth: January 16, 2004\n",
       "- Languages: French, English​TOEIC: 731/990-, Spanish\n",
       "\n",
       "Education:\n",
       "- Master of Data Science and Artificial Intelligence | UPE C & Créteil, 2023\n",
       "- License in Economic and Management | UPE C & CRETIL, 2023 \n",
       "- Master of Machine Learning and Deep Learning | Spark and Logique et Programmation, 2022\n",
       "- Master of Data Economics and Analytics | Master's Degree in Data Science and Artificial Intelligence, 2022\n",
       "- Bachelor's degree in Economic and Management | Lycée Jean-Baptiste Corot, Savigny-sur-Orge, 2020\n",
       "\n",
       "Certifications:\n",
       "- Juror of Double Dutch Certification | Federation Française de Double Dutch, 2020\n",
       "\n",
       "Skills:\n",
       "- Advanced knowledge of data science and artificial intelligence tools and platforms\n",
       "- Proficient in programming languages such as Spark and Logique\n",
       "- Experience with machine learning algorithms and deep learning methodologies\n",
       "- Expertise in macro and microeconomics, stochastic processes, and financial economics\n",
       "- Strong analytical and problem-solving skills\n",
       "- Ability to work independently and as part of a team\n",
       "- Excellent communication skills in French and English\n",
       "\n",
       "Work Experience:\n",
       "- Data Science and Artificial Intelligence Intern | UPE C & Créteil, 2023\n",
       "- Machine Learning and Deep Learning Intern | Spark, 2022\n",
       "- Economic and Management Intern | Lycée Jean-Baptiste Corot, Savigny-sur-Orge, 2020\n",
       "\n",
       "Projects/Internships/Volunteer Experience:\n",
       "- Grigny McDonald's | Crew Member, 2024\n",
       "- Bricoman Monthlery | Sales Assistant, 2022\n",
       "- No Limit Jump | Assistant Event Coordinator, 2020\n",
       "\n",
       "In respect of your criteria, I have laid out the given information in the respective sections of the CV. I remain hesitant to make any alterations to the information you've provided me with. "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.llms import Cohere\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import CohereEmbeddings\n",
    "\n",
    "def generate_cv2(query, vectorstore, cohere_api_key, temperature=0.7, max_tokens=2000):\n",
    "    \"\"\"\n",
    "    Utilise un LLM pour générer un CV basé sur la requête et les documents,\n",
    "    avec des options de personnalisation pour la température et le nombre de tokens.\n",
    "    \"\"\"\n",
    "    # Créer un retriever pour interroger le vectorstore\n",
    "    retriever = vectorstore.as_retriever()\n",
    "\n",
    "    # Définir le prompt qui sera utilisé pour la génération du texte\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"context\", \"query\"],\n",
    "        template=(\n",
    "            \"En se basant sur les informations suivantes : {context}\\n\"\n",
    "            \"Répondez à la requête suivante : {query}\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Ajouter le user_agent\n",
    "    user_agent = \"mon_client\"  # Choisissez un nom pour le client\n",
    "\n",
    "    # Créer les embeddings avec le user_agent\n",
    "    cohere_embeddings = CohereEmbeddings(cohere_api_key=cohere_api_key, user_agent=user_agent)\n",
    "\n",
    "    # Créer le modèle Cohere pour la génération de texte\n",
    "    llm = Cohere(\n",
    "        cohere_api_key=cohere_api_key,  # Utilisation de la clé API directement ici\n",
    "        model=\"command-xlarge\",  # Spécifiez le modèle de génération approprié\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens\n",
    "    )\n",
    "\n",
    "    # Créer la chaîne de question-réponse avec les paramètres de température et de tokens\n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        chain_type=\"stuff\",  # Cette méthode combine les documents\n",
    "        retriever=retriever,\n",
    "        return_source_documents=False\n",
    "    )\n",
    "\n",
    "    # Exécuter la chaîne pour obtenir la réponse\n",
    "    response = qa_chain.run(query)\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "# Exemple d'utilisation de la fonction avec des paramètres modifiables\n",
    "if __name__ == \"__main__\":\n",
    "    # Configurer la clé API Cohere\n",
    "    COHERE_API_KEY = \"IiVPAkCJc5XsF4abBihOzkj2I7WcYKVH4KgLZMID\"\n",
    "\n",
    "    # Exemple de documents fictifs (remplacez-les par vos vrais documents)\n",
    "    documents = [\"Voici une expérience de travail.\", \"Voici une certification acquise.\"]\n",
    "\n",
    "    # Créer un vectorstore avec FAISS et CohereEmbeddings\n",
    "    embeddings = CohereEmbeddings(cohere_api_key=COHERE_API_KEY, user_agent=\"mon_client\")\n",
    "    vectorstore = FAISS.from_documents(documents3, embeddings)\n",
    "\n",
    "    # Générer un CV basé sur une requête utilisateur avec des paramètres de température et de tokens\n",
    "    query = '''Créer un CV basé sur mes expériences et certificats en respectant ce plan :\n",
    "    1- Information \n",
    "    2 - Education \n",
    "    3- Certifications\n",
    "    4 - Skills\n",
    "    5 - Work Experience\n",
    "    6 - Projects/Internships/Volunteer Experience '''\n",
    "    generated_cv = generate_cv2(query, vectorstore, COHERE_API_KEY, temperature=0.7, max_tokens=2000)\n",
    "\n",
    "    # Afficher le CV généré en Markdown\n",
    "    print(\"\\n### CV Généré :\\n\")\n",
    "    markdown_cv = f\"\"\"\n",
    "    # Curriculum Vitae\n",
    "\n",
    "    {generated_cv}\n",
    "    \"\"\"\n",
    "    display(Markdown(generated_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "8626c323-c9fa-4bfc-93ae-9b4b34db0f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### CV Généré :\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       " Sure, I can help you create a basic CV based on the information you've provided. Here's a draft of how such a document could be structured:\n",
       "\n",
       "---\n",
       "\n",
       "**Assa Traore**\n",
       "\n",
       "Email: assa16@gmail.com \n",
       "\n",
       "Phone: (07 69 88 07 32) \n",
       "\n",
       "---\n",
       "\n",
       "# INFORMATION\n",
       "- Date of Birth: 16/01/2004\n",
       "- Languages: English (& TOEIC score 731/990), Spanish\n",
       "- Residential Address: Grigny (91350) \n",
       "\n",
       "# EDUCATION\n",
       "- Master of Data Analysis, UPE C & M Créteil\n",
       "- Licence économie et gestion, UPE C & M Créteil\n",
       "- Master of Artificielle Intelligence, UPE C & M Créteil\n",
       "- Master of Machine Learning, UPE C & M Créteil\n",
       "- Master of Deep Learning, UPE C & M Créteil\n",
       "- Master of Algorithmic Innovation, UPE C & M Créteil\n",
       "- Master of Logiciel Language, UPE C & M Créteil\n",
       "\n",
       "# CERTIFICATIONS\n",
       "- Cert. in Economic Sciences, Lycee Jean-Baptiste Corot Savigny-sur-Orge\n",
       "- Cert. in Mathematical, Statistical and Economic Sciences, Lycee Jean-Baptiste Corot Savigny-sur-Orge\n",
       "- Cert. in TOEIC, Lycee Jean-Baptiste Corot Savigny-sur-Orge\n",
       "- Cert. in Double Dutch Judging, Federation Française de Double Dutch (FFDD), 2020\n",
       "\n",
       "# SKILLS\n",
       "- Data analytics and statistical analysis\n",
       "- Economic analysis and finance comprehension\n",
       "- Project management and event planning\n",
       "- Language interpretation and translation\n",
       "- Software engineering (Java, Python, Spark) \n",
       "- Artificial intelligence and machine learning \n",
       "- Deep learning algorithm design and deployment \n",
       "\n",
       "# WORK EXPERIENCE\n",
       "\n",
       "## Economic and Financial Analyst, DU - Intelligence Artificielle, UPE C & M Créteil\n",
       "- Analyzed large datasets to identify trends and patterns in economic and financial data\n",
       "- Developed predictive models and conducted risk assessments to support strategic decision-making\n",
       "- Collaborated with cross-functional teams to design and implement data-driven solutions for clients\n",
       "\n",
       "## Maire de Grigny, Grigny\n",
       "\n",
       "### Aide aux de voirs\n",
       "\n",
       "- Assisted with administrative tasks related to the municipality's economic development initiatives\n",
       "\n",
       "### Mise en place des événements sportifs et culturels\n",
       "\n",
       "- Planned and organized sports and cultural events for children unable to attend summer holidays due to the COVID-19 pandemic\n",
       "\n",
       "## No Limit Jump, Grigny\n",
       "\n",
       "### Aide aux révisions \n",
       "\n",
       "- Assisted students with lesson revisions and provided supplementary exercises\n",
       "\n",
       "### Apprentissage des leçons \n",
       "\n",
       "- Assisted with lesson preparation and delivered classroom support\n",
       "\n",
       "## Hôtesse de caisse, Bricoman Monthlery\n",
       "\n",
       "### Encaissement de la clientèle\n",
       "\n",
       "- Managed cash register operations, including inventory and control of stocks\n",
       "\n",
       "### Gestion des retours \n",
       "\n",
       "- Managed return processes and ensured high levels of customer satisfaction \n",
       "\n",
       "## Conseillère clientèle, Amazon Brétigny-sur-Orge\n",
       "\n",
       "### Contrôle de la qualité\n",
       "\n",
       "- Ensured consistent quality control of stocks and monitored water levels\n",
       "\n",
       "### Suivi de niveaux de stocks \n",
       "\n",
       "- Conducted inventory checks and organized stock storage\n",
       "\n",
       "### Préparation des commandes\n",
       "\n",
       "- Prepared orders for shipping and managed customer orders \n",
       "\n",
       "## Spécialiste Math, SES, HGGSP, Lycee Jean-Baptiste Corot Savigny-sur-Orge \n",
       "\n",
       "### Service Civique\n",
       "\n",
       "- Taught mathematics to students and assisted with homework\n",
       "\n",
       "## Licenciée en Microéconomie, Macroéconomie, Processus Stochastique, UPE C & M Créteil \n",
       "\n",
       "### Économétrie\n",
       "\n",
       "- Analyzed economic data to forecast market trends and consumer behaviour \n",
       "\n",
       "### Financé\n",
       "\n",
       "- Evaluated financial statements and assessed corporate investment strategies \n",
       "\n",
       "# PROJECTS/INTERNSHIPS/VOLUNTEER EXPERIENCE\n",
       "\n",
       "## Master of Licence économie et gestion, UPE C & M Créteil\n",
       "\n",
       "###Dissertation:  \"Title of Dissertation\" (Expected Graduation: 2024)\n",
       "\n",
       "## TOEIC Certification, Lycee Jean-Baptiste Corot Savigny-sur-Orge\n",
       "\n",
       "### Translation and Interpretation\n",
       "\n",
       " facilitated communication between French and English speakers. \n",
       "\n",
       "## Certification in Double Dutch Judging, Federation Française de Double Dutch (FFDD), 2020\n",
       "\n",
       "### Sports Event Planning and Management\n",
       "\n",
       "Assisted with organizing local Double Dutch competitions and judged during events. \n",
       "\n",
       "## Master of Licence économie et gestion, UPE C & M Créteil\n",
       "\n",
       "### Economic Research Intern, Institute for Economic Research (IEP), 2023 \n",
       "\n",
       "## Licenciée en Microéconomie, Macroéconomie, Processus Stochastique, UPE C & M Créteil\n",
       "\n",
       "### Volunteer, Refugee Support Organization, 2022\n",
       "\n",
       "Please note that this draft is just a starting point. You may want to customize and expand each section with more details, particularly the \"Work Experience\" and \"Projects/Internships/Volunteer Experience\" parts. Additionally, you can format and organize these sections according to your preferences or resume standards specific to your country or industry. "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.llms import Cohere\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import CohereEmbeddings\n",
    "\n",
    "def generate_cv2(query, vectorstore, cohere_api_key, temperature=0.4, max_tokens=2000):\n",
    "    \"\"\"\n",
    "    Utilise un LLM pour générer un CV basé sur la requête et les documents,\n",
    "    avec des options de personnalisation pour la température et le nombre de tokens.\n",
    "    \"\"\"\n",
    "    # Créer un retriever pour interroger le vectorstore\n",
    "    retriever = vectorstore.as_retriever()\n",
    "\n",
    "    # Définir le prompt qui sera utilisé pour la génération du texte\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"context\", \"query\"],\n",
    "        template=(\n",
    "            \"En se basant sur les informations suivantes : {context}\\n\"\n",
    "            \"Répondez à la requête suivante : {query}\"\n",
    "        )\n",
    "    )\n",
    "    # Ajouter le user_agent\n",
    "    user_agent = \"mon_client\"  # Choisissez un nom pour le client\n",
    "\n",
    "    # Créer les embeddings avec le user_agent\n",
    "    cohere_embeddings = CohereEmbeddings(cohere_api_key=cohere_api_key, user_agent=user_agent)\n",
    "\n",
    "    # Créer le modèle Cohere pour la génération de texte\n",
    "    llm = Cohere(\n",
    "        cohere_api_key=cohere_api_key,  # Utilisation de la clé API directement ici\n",
    "        model=\"command-xlarge\",  # Spécifiez le modèle de génération approprié\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens\n",
    "    )\n",
    "\n",
    "    # Créer la chaîne de question-réponse avec les paramètres de température et de tokens\n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        chain_type=\"stuff\",  # Cette méthode combine les documents\n",
    "        retriever=retriever,\n",
    "        return_source_documents=False\n",
    "    )\n",
    "    # Exécuter la chaîne pour obtenir la réponse\n",
    "    response = qa_chain.run(query)\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "# Exemple d'utilisation de la fonction avec des paramètres modifiables\n",
    "if __name__ == \"__main__\":\n",
    "    # Configurer la clé API Cohere\n",
    "    COHERE_API_KEY = \"IiVPAkCJc5XsF4abBihOzkj2I7WcYKVH4KgLZMID\"\n",
    "\n",
    "    # Créer un vectorstore avec FAISS et CohereEmbeddings\n",
    "    embeddings = CohereEmbeddings(cohere_api_key=COHERE_API_KEY, user_agent=\"mon_client\")\n",
    "    vectorstore = FAISS.from_documents(documents3, embeddings)\n",
    "\n",
    "    # Générer un CV basé sur une requête utilisateur avec des paramètres de température et de tokens\n",
    "    query = '''Créer un CV basé sur mes expériences et certificats en respectant ce plan :\n",
    "    1- Information \n",
    "    2 - Education \n",
    "    3- Certifications\n",
    "    4 - Skills\n",
    "    5 - Work Experience\n",
    "    6 - Projects/Internships/Volunteer Experience '''\n",
    "    generated_cv = generate_cv2(query, vectorstore, COHERE_API_KEY, temperature=0.7, max_tokens=2000)\n",
    "\n",
    "    # Afficher le CV généré en Markdown\n",
    "    print(\"\\n### CV Généré :\\n\")\n",
    "    markdown_cv = f\"\"\"\n",
    "    # Curriculum Vitae\n",
    "\n",
    "    {generated_cv}\n",
    "    \"\"\"\n",
    "    display(Markdown(generated_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "1d116b1d-7d7f-4bf0-bfad-1fc50bfe99a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 00:56:11.962 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-08 00:56:11.963 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-08 00:56:56.885 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-08 00:56:56.886 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-08 00:56:56.887 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-08 00:56:56.887 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import Cohere\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import CohereEmbeddings\n",
    "import streamlit as st  # Import Streamlit pour afficher en Markdown\n",
    "\n",
    "def generate_cv2(query, vectorstore, cohere_api_key, temperature=0.4, max_tokens=2000):\n",
    "    \"\"\"\n",
    "    Utilise un LLM pour générer un CV basé sur la requête et les documents,\n",
    "    avec des options de personnalisation pour la température et le nombre de tokens.\n",
    "    \"\"\"\n",
    "    # Créer un retriever pour interroger le vectorstore\n",
    "    retriever = vectorstore.as_retriever()\n",
    "\n",
    "    # Définir le prompt qui sera utilisé pour la génération du texte\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"context\", \"query\"],\n",
    "        template=(\n",
    "            \"En se basant sur les informations suivantes : {context}\\n\"\n",
    "            \"Répondez à la requête suivante : {query}\"\n",
    "        )\n",
    "    )  # Ajouter le user_agent\n",
    "    user_agent = \"mon_client\"  # Choisissez un nom pour le client\n",
    "\n",
    "    # Créer les embeddings avec le user_agent\n",
    "    cohere_embeddings = CohereEmbeddings(cohere_api_key=cohere_api_key, user_agent=user_agent)\n",
    "\n",
    "    # Créer le modèle Cohere pour la génération de texte\n",
    "    llm = Cohere(\n",
    "        cohere_api_key=cohere_api_key,  # Utilisation de la clé API directement ici\n",
    "        model=\"command-xlarge\",  # Spécifiez le modèle de génération approprié\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens\n",
    "    )\n",
    "    # Créer la chaîne de question-réponse avec les paramètres de température et de tokens\n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        chain_type=\"stuff\",  # Cette méthode combine les documents\n",
    "        retriever=retriever,\n",
    "        return_source_documents=False\n",
    "    )\n",
    "    # Exécuter la chaîne pour obtenir la réponse\n",
    "    response = qa_chain.run(query)\n",
    "\n",
    "    return response\n",
    "\n",
    "# Exemple d'utilisation de la fonction avec Streamlit\n",
    "if __name__ == \"__main__\":\n",
    "    # Configurer la clé API Cohere\n",
    "    COHERE_API_KEY = \"IiVPAkCJc5XsF4abBihOzkj2I7WcYKVH4KgLZMID\"\n",
    "\n",
    "    # Titre de l'application\n",
    "    st.title(\"Générateur de CV\")\n",
    "\n",
    "    # Créer un vectorstore avec FAISS et CohereEmbeddings\n",
    "    embeddings = CohereEmbeddings(cohere_api_key=COHERE_API_KEY, user_agent=\"mon_client\")\n",
    "    vectorstore = FAISS.from_documents(documents3, embeddings)\n",
    "\n",
    "    # Générer un CV basé sur une requête utilisateur avec des paramètres de température et de tokens\n",
    "    query = \"Créer un CV basé sur mes expériences et certificats\"\n",
    "    generated_cv = generate_cv2(query, vectorstore, COHERE_API_KEY, temperature=0.7, max_tokens=2000)\n",
    "\n",
    "    # Afficher le CV généré dans un conteneur Markdown\n",
    "    st.markdown(\"## CV Généré\")\n",
    "    st.markdown(generated_cv)  # Le CV est affiché en Markdown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "45be7b25-257c-4e07-829a-3068a810a8dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### CV Généré :\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       " Sure, I can help you create a basic CV based on the information you've provided. Please note that a CV for a French context may differ from that in other countries, so this may not be a perfect match for what you are seeking. Here is a draft of a CV following the structure you require: \n",
       "\n",
       "---\n",
       "**Information**\n",
       "- Name: Assa Traore\n",
       "- Address: Grigny (91350) \n",
       "- Phone: Ile-de-France 07 69 88 07 32\n",
       "- Email: assa16@gmail.com\n",
       "- Date of Birth: 16/01/2004\n",
       "\n",
       "**Education**\n",
       "- Master MASERA TI UPE C, Data Analysis, Créteil\n",
       "- Licence économie e t gestion, UPE C, Créteil\n",
       "- Lycée Jean-Baptiste Corot, Savigny-sur -Orge, Baccalaur éat, Maths - SES - HGGSP\n",
       "\n",
       "**Certifications**\n",
       "- Certificate of Formation as a Judge for Double Dutch, December 2020. \n",
       "- Language certifications (TOEIC: 731/990, Español)\n",
       "\n",
       "**Skills**\n",
       "- Data analysis\n",
       "- Software and language programming (Logique e t programma tion)\n",
       "- Algorithme a vancée\n",
       "- Economic analysis (Microéconomie Macroéconomie)\n",
       "- Communication (TOEIC: 731/990)\n",
       "- Leadership \n",
       "- Event organization \n",
       "\n",
       "**Work Experience**\n",
       "- Aide aux de voirs, Maire de G rigny, Grigny. \n",
       "- Apprentissage des leçons, Aide à l'apprentissage des leçons, Hôtesse de caisse Bricoman Monthléry.\n",
       "- Inventaire et contrôle des niv eaux des st ocks, Applica tion des pr océdures de f erme ture, Brétigny-sur -Orge.\n",
       "- Conseille clien tèle, Gestion des c ommandes driv e, Sonink é, Langue ma ternelle Anglais. \n",
       "\n",
       "**Projects/Internships/Volunteer Experience**\n",
       "- Mise en plac e d'événemen ts sportifs e t cultur elles pour les en fants n'ayant pas pu aller en vacanc es à cause du c ontexte pandémique de cet été, Grigny. \n",
       "- Accompagnemen t des élè ves dans leur s révisions, Propositions d' exercices supplémen taires, Aide à l'apprentissag e des leçons, Équipièr e polyv alente McDonald's, Grigny. \n",
       "\n",
       "--- \n",
       "Please note that this is just a starting point and you may want to edit and expand on these points to create a more detailed and personalised CV. \n",
       "Let me know if you would like me to proceed to the next steps and add more information or edit the existing copy. \n",
       "I can also advice on how to include specific information in a CV for French contexts if this is what you are seeking. Do you need advice for further sections or would you like me to start removing identifying information for privacy? "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.llms import Cohere\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import CohereEmbeddings\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "def generate_cv2(query, vectorstore, cohere_api_key, temperature=0.4, max_tokens=2000):\n",
    "    \"\"\"\n",
    "    Utilise un LLM pour générer un CV basé sur la requête et les documents,\n",
    "    avec des options de personnalisation pour la température et le nombre de tokens.\n",
    "    \"\"\"\n",
    "    # Créer un retriever pour interroger le vectorstore\n",
    "    retriever = vectorstore.as_retriever()\n",
    "\n",
    "    # Définir le prompt qui sera utilisé pour la génération du texte\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"context\", \"query\"],\n",
    "        template=(\n",
    "            \"En se basant sur les informations suivantes : {context}\\n\"\n",
    "            \"Répondez à la requête suivante : {query}\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Ajouter le user_agent\n",
    "    user_agent = \"mon_client\"  # Choisissez un nom pour le client\n",
    "\n",
    "    # Créer les embeddings avec le user_agent\n",
    "    cohere_embeddings = CohereEmbeddings(cohere_api_key=cohere_api_key, user_agent=user_agent)\n",
    "\n",
    "    # Créer le modèle Cohere pour la génération de texte\n",
    "    llm = Cohere(\n",
    "        cohere_api_key=cohere_api_key,  # Utilisation de la clé API directement ici\n",
    "        model=\"command-xlarge\",  # Spécifiez le modèle de génération approprié\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens\n",
    "    )\n",
    "\n",
    "    # Créer la chaîne de question-réponse avec les paramètres de température et de tokens\n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        chain_type=\"stuff\",  # Cette méthode combine les documents\n",
    "        retriever=retriever,\n",
    "        return_source_documents=False\n",
    "    )\n",
    "    \n",
    "    # Exécuter la chaîne pour obtenir la réponse\n",
    "    response = qa_chain.run(query)\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "# Exemple d'utilisation de la fonction avec des paramètres modifiables\n",
    "if __name__ == \"__main__\":\n",
    "    # Configurer la clé API Cohere\n",
    "    COHERE_API_KEY = \"IiVPAkCJc5XsF4abBihOzkj2I7WcYKVH4KgLZMID\"\n",
    "\n",
    "\n",
    "    embeddings = CohereEmbeddings(cohere_api_key=COHERE_API_KEY, user_agent=\"mon_client\")\n",
    "    vectorstore = FAISS.from_documents(documents3, embeddings)\n",
    "\n",
    "    # Générer un CV basé sur une requête utilisateur avec des paramètres de température et de tokens\n",
    "    query = '''Créer un CV basé sur mes expériences et certificats en respectant ce plan :\n",
    "    1- Information \n",
    "    2 - Education \n",
    "    3- Certifications\n",
    "    4 - Skills\n",
    "    5 - Work Experience\n",
    "    6 - Projects/Internships/Volunteer Experience '''\n",
    "    generated_cv = generate_cv2(query, vectorstore, COHERE_API_KEY, temperature=0.7, max_tokens=2000)\n",
    "\n",
    "    # Afficher le CV généré en Markdown\n",
    "    print(\"\\n### CV Généré :\\n\")\n",
    "    markdown_cv = f\"\"\"\n",
    "    # Curriculum Vitae\n",
    "\n",
    "    {generated_cv}\n",
    "    \"\"\"\n",
    "    display(Markdown(generated_cv))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
